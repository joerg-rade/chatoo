Hereâ€™s a compact, highâ€‘signal overview of **small, localâ€‘friendly models that actually support tool/function calling** when used through runtimes like Ollama or other inference servers. Iâ€™ve focused on models that are practical for your LibreChat + MCP setup and that run well on consumer hardware.

---

# ğŸ“Š **Overview Table: Small Models With Tool Support**

| Model | Size | Tool / Function Calling | Typical Hardware Requirements | License |
|------|------|--------------------------|-------------------------------|---------|
| **Llama 3.1 Instruct** | 8B | âœ” Fully supported (structured JSON, tools) | 8â€“12 GB RAM (CPU) or 6â€“8 GB VRAM (GPU) | Meta Llama 3.1 Community License |
| **Qwen2.5 Instruct** | 7B | âœ” Very strong tool calling | 8â€“12 GB RAM or 6â€“8 GB VRAM | Apache 2.0 |
| **Qwen2.5 Instruct** | 14B | âœ” Excellent tool calling | 16â€“20 GB RAM or 12â€“16 GB VRAM | Apache 2.0 |
| **Gemma 2 Instruct** | 9B | âœ” Good structured output & tools | 12â€“16 GB RAM or 8â€“10 GB VRAM | Gemma License (permissive but not fully open) |
| **Mistral Nemo** | 12B | âœ” Reliable tool calling | 16â€“20 GB RAM or 12â€“16 GB VRAM | Apache 2.0 |
| **Llama 2 Chat** | 7B | âœ” Partial tool support (works, but less reliable) | 8â€“12 GB RAM or 6â€“8 GB VRAM | Llama 2 Community License |
| **Mistral Instruct** | 7B | âœ” Partial tool support | 8â€“12 GB RAM or 6â€“8 GB VRAM | Apache 2.0 |

---

# ğŸ§  Notes on Practical Use

### âœ” Best overall small model for tools
**Qwen2.5 7B Instruct**
- Apache 2.0
- Very strong JSON adherence
- Runs fast on modest hardware
- Excellent for MCP tool workflows

### âœ” Best balance of quality + size
**Llama 3.1 8B Instruct**
- Great reasoning
- Good tool calling
- Slightly heavier than Qwen2.5 7B

### âœ” Best â€œopenâ€‘sourceâ€ licensing
**Qwen2.5 (7B/14B)** and **Mistral Nemo**
- Both Apache 2.0
- No usage restrictions

### âœ” Models to avoid for tool calling
- Phiâ€‘3 (all sizes)
- Phiâ€‘2
- Base models (nonâ€‘instruct)
- Most GGUF conversions without tool metadata

These will trigger the error you saw in LibreChat.

---

If you want, I can help you pick the best model for your exact hardware and workload so your LibreChat + MCP setup runs smoothly.
